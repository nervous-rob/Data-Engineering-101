# Lesson 4.2: Spark DataFrames and SQL

## Navigation
- [← Back to Module Overview](./README.md)
- [Previous Lesson ←](./4.1-apache-spark-fundamentals.md)
- [Next Lesson →](./4.3-etl-pipeline-development.md)

## Learning Objectives
- Master Spark DataFrames API and operations
- Learn Spark SQL capabilities and syntax
- Understand DataFrame optimization techniques
- Practice common data transformation patterns

## Detailed Content
- [Read Full Lecture Notes](./lectures/lesson-4-2.md)

## Key Concepts

### Spark DataFrames
- Structured data abstraction
- Schema-based data organization
- Built-in optimization (Catalyst optimizer)
- Integration with Spark SQL

### DataFrame Operations
- Transformations and actions
- Column operations
- Window functions
- Aggregations and joins

### Spark SQL
- SQL query interface
- Temporary views
- UDFs (User Defined Functions)
- Integration with external data sources

### Performance Optimization
- Partition pruning
- Predicate pushdown
- Column pruning
- Broadcast joins

## Hands-on Exercises

### Exercise 1: Working with DataFrames
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, count

# Create sample DataFrame
data = [
    (1, "John", 30),
    (2, "Jane", 25),
    (3, "Bob", 35)
]
df = spark.createDataFrame(data, ["id", "name", "age"])

# Basic operations
filtered_df = df.filter(col("age") > 25)
grouped_df = df.groupBy("age").agg(
    count("*").alias("count"),
    avg("id").alias("avg_id")
)
```

### Exercise 2: Spark SQL Queries
```python
# Register DataFrame as temporary view
df.createOrReplaceTempView("users")

# SQL query
result = spark.sql("""
    SELECT age, COUNT(*) as count
    FROM users
    WHERE age > 25
    GROUP BY age
    ORDER BY age DESC
""")
```

## Best Practices
- Use appropriate data types
- Leverage built-in functions
- Implement proper partitioning
- Monitor query performance
- Use broadcast joins for small tables

## Common Pitfalls
- Inefficient join operations
- Excessive data shuffling
- Improper schema design
- Memory-intensive operations

## Additional Resources
- Spark SQL Documentation
- DataFrame API Reference
- Performance Tuning Guide
- Community Best Practices

## Next Steps
- Explore advanced SQL features
- Learn about custom UDFs
- Practice with complex queries
- Understand query optimization 