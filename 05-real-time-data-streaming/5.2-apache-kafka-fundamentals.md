# Lesson 5.2: Apache Kafka Fundamentals

## Navigation
- [← Back to Module Overview](./README.md)
- [Previous Lesson ←](./5.1-introduction-to-data-streaming.md)
- [Next Lesson →](./5.3-advanced-kafka-concepts.md)

## Learning Objectives
- Understand Kafka's core concepts and architecture
- Master topics, partitions, and brokers
- Learn about producer and consumer patterns
- Practice basic Kafka operations

## Detailed Content
- [Read Full Lecture Notes](./lectures/lesson-5-2.md)

## Key Concepts

### Kafka Architecture
- Brokers and clusters
- Topics and partitions
- Replication
- Zookeeper integration
- Message storage

### Core Components
- Producers
- Consumers
- Consumer groups
- Topic management
- Partition management

### Message Handling
- Message format
- Serialization
- Compression
- Delivery guarantees
- Offset management

### Kafka Configuration
- Broker settings
- Topic configurations
- Producer settings
- Consumer settings
- Performance tuning

## Hands-on Exercises

### Exercise 1: Basic Kafka Producer
```python
from kafka import KafkaProducer
import json
import time

def create_producer():
    producer = KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda v: json.dumps(v).encode('utf-8'),
        acks='all',
        retries=3
    )
    return producer

def send_messages():
    producer = create_producer()
    
    # Generate and send messages
    for i in range(10):
        message = {
            'id': i,
            'timestamp': time.time(),
            'value': f'Message {i}'
        }
        
        # Send message
        producer.send('test-topic', message)
        producer.flush()
        
        print(f"Sent message: {message}")
    
    producer.close()
```

### Exercise 2: Basic Kafka Consumer
```python
from kafka import KafkaConsumer
import json

def create_consumer():
    consumer = KafkaConsumer(
        'test-topic',
        bootstrap_servers=['localhost:9092'],
        group_id='test-group',
        auto_offset_reset='earliest',
        value_deserializer=lambda x: json.loads(x.decode('utf-8'))
    )
    return consumer

def consume_messages():
    consumer = create_consumer()
    
    try:
        # Consume messages
        for message in consumer:
            print(f"Received message: {message.value}")
            
    except KeyboardInterrupt:
        print("Stopping consumer...")
    finally:
        consumer.close()
```

## Best Practices
- Use appropriate partition strategy
- Implement proper error handling
- Monitor consumer lag
- Configure appropriate batch sizes
- Use compression when needed

## Common Pitfalls
- Poor partition strategy
- Missing error handling
- Consumer group issues
- Performance bottlenecks
- Configuration problems

## Additional Resources
- Kafka Documentation
- Producer/Consumer Guide
- Performance Tuning Guide
- Best Practices Reference

## Next Steps
- Learn about advanced Kafka features
- Explore stream processing
- Practice with real scenarios
- Understand monitoring tools 